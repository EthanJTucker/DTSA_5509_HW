{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dc5666374ee06578ae8c0132b757feb",
     "grade": false,
     "grade_id": "cell-05b7e07a206343a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment.<br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afa9bafbf299bdf37786267ab7e523f1",
     "grade": false,
     "grade_id": "cell-d914ec0c7e3d35e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "Please note that this assignment uses nbgrader to facilitate grading. You will see a **validate button** at the top of your Jupyter notebook. If you hit this button, it will run tests cases for the lab that aren't hidden. It is good to use the validate button before submitting the lab. Do know that the labs in the course contain hidden test cases. The validate button will not let you know whether these test cases pass. After submitting your lab, you can see more information about these hidden test cases in the Grader Output. <br>\n",
    "***Cells with longer execution times will cause the validate button to time out and freeze. Please know that if you run into Validate time-outs, it will not affect the final submission grading.*** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "321b33afccdc07ce06f906cb4ba4083b",
     "grade": false,
     "grade_id": "cell-0a9bd55375e1d2fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 6: Support Vector Machines \n",
    "***\n",
    "\n",
    "In this assignment we'll explore the details of the Soft-Margin SVM and look at how the choice of tuning parameters  affects the learned models.  We'll also look at kernel SVMs for non-linearly separable and methods for choosing and visualizing good hyperparameters.   \n",
    "\n",
    "**Note**: Below are some helper functions which are used throughout this notebook.  Execute these before continuing. Do not modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea89d2e91f48c5e32ccd30129f84ad34",
     "grade": false,
     "grade_id": "cell-7ca30e1703520b3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def linear_plot(X, y, w=None, b=None):\n",
    "    \n",
    "    mycolors = {\"blue\": \"steelblue\", \"red\": \"#a76c6e\", \"green\": \"#6a9373\"}\n",
    "    colors = [mycolors[\"red\"] if yi==1 else mycolors[\"blue\"] for yi in y]\n",
    "    \n",
    "    # Plot data \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "    ax.scatter(X[:,0], X[:,1], color=colors, s=150, alpha=0.95, zorder=2)\n",
    "    \n",
    "    # Plot boundaries \n",
    "    lower_left = np.min([np.min(X[:,0]), np.min(X[:,1])])\n",
    "    upper_right = np.max([np.max(X[:,0]), np.max(X[:,1])])\n",
    "    gap = .1*(upper_right-lower_left)\n",
    "    xplot = np.linspace(lower_left-gap, upper_right+gap, 20)\n",
    "    if w is not None and b is not None: \n",
    "        ax.plot(xplot, (-b - w[0]*xplot)/w[1], color=\"gray\", lw=2, zorder=1)\n",
    "        ax.plot(xplot, ( 1 -b - w[0]*xplot)/w[1], color=\"gray\", lw=2, ls=\"--\", zorder=1)\n",
    "        ax.plot(xplot, (-1 -b - w[0]*xplot)/w[1], color=\"gray\", lw=2, ls=\"--\", zorder=1)\n",
    "        \n",
    "    \n",
    "    ax.set_xlim([lower_left-gap, upper_right+gap])\n",
    "    ax.set_ylim([lower_left-gap, upper_right+gap])\n",
    "    \n",
    "    ax.grid(alpha=0.25)\n",
    "    \n",
    "def part2data():\n",
    "    \n",
    "    np.random.seed(1239)\n",
    "    \n",
    "    X = np.zeros((22,2))\n",
    "    X[0:10,0]  = 1.5*np.random.rand(10) \n",
    "    X[0:10,1]  = 1.5*np.random.rand(10)\n",
    "    X[10:20,0] = 1.5*np.random.rand(10) +  1.75\n",
    "    X[10:20,1] = 1.5*np.random.rand(10) +  1\n",
    "    X[20,0] = 1.5\n",
    "    X[20,1] = 2.25\n",
    "    X[21,0] = 1.6\n",
    "    X[21,1] = 0.25\n",
    "    \n",
    "    y = np.ones(22)\n",
    "    y[10:20] = -1 \n",
    "    y[20] = 1\n",
    "    y[21] = -1\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def part3data(N=100, seed=1235):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X = np.random.uniform(-1,1,(N,2))\n",
    "    y = np.array([1 if y-x > 0 else -1 for (x,y) in zip(X[:,0]**2 * np.sin(2*np.pi*X[:,0]), X[:,1])])\n",
    "    X = X + np.random.normal(0,.1,(N,2))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def nonlinear_plot(X, y, clf=None): \n",
    "    \n",
    "    mycolors = {\"blue\": \"steelblue\", \"red\": \"#a76c6e\", \"green\": \"#6a9373\"}\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,10))\n",
    "    \n",
    "    colors = [mycolors[\"red\"] if yi==1 else mycolors[\"blue\"] for yi in y]\n",
    "    ax.scatter(X[:,0],X[:,1], marker='o', color=colors, s=100, alpha=0.5)\n",
    "    \n",
    "    ax.arrow(-1.25,0,2.5,0, head_length=0.05, head_width=0.05, fc=\"gray\", ec=\"gray\", lw=2, alpha=0.25)\n",
    "    ax.arrow(0,-1.25,0,2.5, head_length=0.05, head_width=0.05, fc=\"gray\", ec=\"gray\", lw=2, alpha=0.25)\n",
    "    z = np.linspace(0.25,3.5,10)\n",
    "    \n",
    "    ax.set_xlim([-1.50,1.50])\n",
    "    ax.set_ylim([-1.50,1.50])\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    plt.xticks([], fontsize=16)\n",
    "    plt.yticks([], fontsize=16)\n",
    "    \n",
    "\n",
    "    if clf: \n",
    "        \n",
    "        clf.fit(X,y)\n",
    "\n",
    "        x_min = X[:, 0].min()+.00\n",
    "        x_max = X[:, 0].max()-.00\n",
    "        y_min = X[:, 1].min()+.00\n",
    "        y_max = X[:, 1].max()-.00\n",
    "\n",
    "        colors = [mycolors[\"red\"] if yi==1 else mycolors[\"blue\"] for yi in y]\n",
    "\n",
    "        XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "        Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(XX.shape)\n",
    "        plt.contour(XX, YY, Z, colors=[mycolors[\"blue\"], \"gray\", mycolors[\"red\"]], linestyles=['--', '-', '--'],\n",
    "                    levels=[-1.0, 0, 1.0], linewidths=[2,2,2], alpha=0.9)\n",
    "    \n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "def plotSearchGrid(grid):\n",
    "    \n",
    "    scores = [x for x in grid.cv_results_[\"mean_test_score\"]]\n",
    "    scores = np.array(scores).reshape(len(grid.param_grid[\"C\"]), len(grid.param_grid[\"gamma\"]))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "               norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "    plt.xlabel('gamma')\n",
    "    plt.ylabel('C')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(grid.param_grid[\"gamma\"])), grid.param_grid[\"gamma\"], rotation=45)\n",
    "    plt.yticks(np.arange(len(grid.param_grid[\"C\"])), grid.param_grid[\"C\"])\n",
    "    plt.title('Validation accuracy')\n",
    "    plt.show()\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".MathJax nobr>span.math>span{border-left-width:0 !important};\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0532d2392b28f547eea3ddc2821d9c26",
     "grade": false,
     "grade_id": "cell-31a3b7024c25101e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 1: SVM [20 pts, Peer Review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c8a95d829160432c82042a8f83c3c9e",
     "grade": false,
     "grade_id": "cell-b209be9ccc230ed7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data and Labels \n",
    "X = np.array([[1,8],[7,2],[6,-1],[-5,0], [-5,1], [-5,2],[6,3],[6,1],[5,2]])\n",
    "y = np.array([1,-1,-1,1,-1,1,1,-1,-1])\n",
    "\n",
    "# Support vector parameters \n",
    "w, b = np.array([-1/4, 1/4]), -1/4\n",
    "\n",
    "# Plot the data and support vector boundaries \n",
    "linear_plot(X, y, w=w, b=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d8f23799c01bb3c5ecae836d791874a",
     "grade": false,
     "grade_id": "cell-4af1c2c8e25b86a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A [5 pts]**: What is the margin of this particular SVM? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "588a2177617b731a573805883ac16e2e",
     "grade": false,
     "grade_id": "cell-d2c22d2902abfd48",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "margin = 0 # update margin to be a correct number\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72fc2301be0bd68630be57817ab37dbb",
     "grade": true,
     "grade_id": "cell-3e98224eab83e882",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests that margin was updated correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0ad74e7b0ddae3e3f38edd74f3d62e6",
     "grade": false,
     "grade_id": "cell-32f1b6b1bd799f14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B [5 pts, Peer Review]**: Which training examples are the support vectors? Assign the coordinate in the list. e.g. support_vectors = [(1,0),(0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc5d2898d0d65101b2417e771bc1fc59",
     "grade": false,
     "grade_id": "cell-f101ca7047e7c8b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# uncomment and update support_vectors  \n",
    "# your code here\n",
    "\n",
    "# support_vectors=[(1,0),(0,0)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4707c2fcc1f319ee875a7a75310cabe8",
     "grade": true,
     "grade_id": "cell-96b9ab3c0b9c7f53",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests support_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13b4b28188cb2d4954c2c2a2fc65e6af",
     "grade": false,
     "grade_id": "cell-cde429d10fa2efff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Answer the following question in this week's **Peer Review assignment**:<br> \n",
    "Explain your answer for which training examples are support vectors. For the support vectors that you have identified, which are the in-bound support vectors and which are the out-bound support vectors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "008afc7d464ca97f272ccb5f1f9c50b4",
     "grade": false,
     "grade_id": "cell-d03112737ef3e441",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instructor testing cell \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9379e10b013b02ef027b8bb8b354abec",
     "grade": false,
     "grade_id": "cell-e10927a9a10f48fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C [5 pts, Peer Review]**: Which training examples have nonzero slack? List their coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab3942a5eb95a2bfa80d47fb01faf25c",
     "grade": false,
     "grade_id": "cell-bf3d5b1c0594a8e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# list of coordinates with nonzero slack \n",
    "nonzero_slack=[]\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8aef65b6c84b0b5e7a7f9ea728181014",
     "grade": true,
     "grade_id": "cell-a8b409e6b2393568",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests nonzero_slack list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "745bcc953f96905976c88a56d44cde71",
     "grade": false,
     "grade_id": "cell-9e73d3eed45f34ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Answer the following question in this week's **Peer Review assignment**: <br>\n",
    "How did you know which training examples had nonzero slack? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd09027eb9e8aedbe8d7f32c49031c38",
     "grade": false,
     "grade_id": "cell-dcf87cd2624d3317",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instructor testing cell\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3eb78c4b12a6a67bfd73c093358a37fb",
     "grade": false,
     "grade_id": "cell-070928c539e32d09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part D [5 pts, Peer Review]**: Compute the slack $\\xi_i$ associated with the misclassified points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ac09f9fab825e2d73a63a608b16c100",
     "grade": false,
     "grade_id": "cell-dc05aeda72d2ddec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# compute the slack associated with the misclassified points\n",
    "# return a list slacks with the slack computations\n",
    "# slacks = [slack1, slack2]\n",
    "# slack1 = \n",
    "# slack2 = \n",
    "print(slacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "830167fd3dc9cbf240a31b53755354da",
     "grade": true,
     "grade_id": "cell-884383beca3f9d0f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests slacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a14e5bc4e859a62153550fe13db23f94",
     "grade": false,
     "grade_id": "cell-ce44c130afd902bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Answer the following question in your **Peer Review assignment for the week**: <br>\n",
    "Do these slack values agree with the plot of the data and the support vector boundaries? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38fe6c5b2134f238fe68685d13d915f8",
     "grade": false,
     "grade_id": "cell-4a15d10c45a74de4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2: The Margin vs Slack \n",
    "***\n",
    "\n",
    "In this problem we'll figure out how to fit linear SVM models to data using sklearn.  Consider the data shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25453a4e89111025ee5001053ea983a8",
     "grade": false,
     "grade_id": "cell-f87ca993405428e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = part2data()\n",
    "linear_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4522ccece7623219417e99ffb7401e34",
     "grade": false,
     "grade_id": "cell-1f081e45c268aaf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A [5 pts]**: Let's fit a linear Soft-Margin SVM to the data above. For SVMs with a linear kernel we'll use the [`LinearSVM`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) method from sklearn's `svm` module.  Go now and look at the documentation. \n",
    "\n",
    "Recall that the primal objective function for the linear kernel SVM is as follows \n",
    "\n",
    "\n",
    "$$\n",
    "\\min_{{\\bf w}, b, {\\bf \\xi}} \\frac{1}{2}\\|{\\bf w}\\|^2 + C \\sum_{i=1}^m \\xi_i^p.\n",
    "$$\n",
    "**Note that the C parameter definition in sklearn is different from the textbook.**\n",
    "\n",
    "The two optional parameters in `LinearSVM` that we'll be most concerned with are `C`, the hyperparameter weighting the slackness contribution to the primal objective function, and `loss`, which determines the exponent on the slack variables in the sum. When $p=1$ from above equation, the loss is hinge loss, whereas is $p=2$, it's $L2$ form, the loss is called squared-hinge.\n",
    "\n",
    "Write some code below to train a linear SVM with $C=1$ and $p=1$, get the computed weight vector and bias, and the plot the resulting model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d926feb1ff0acd4d0fa1330bd3b42f49",
     "grade": false,
     "grade_id": "cell-a8b5a74b427e0a86",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO: Build a LinearSVC model called lsvm. Train the model and get the parameters, pay attention to the loss parameter\n",
    "lsvm = None\n",
    "# your code here\n",
    "\n",
    "\n",
    "# use this code to plot the resulting model\n",
    "w = lsvm.coef_[0]\n",
    "b = lsvm.intercept_\n",
    "print(w,b)\n",
    "linear_plot(X, y, w=w, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25eb1c5dd0d4916de32c208d43fd54da",
     "grade": true,
     "grade_id": "cell-5df97e1fbfc866fc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests w and b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8f5c4ba13eb5737ae6afbc4b2bc0cff",
     "grade": false,
     "grade_id": "cell-42d9f20f45c886c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B**: Experiment with different values of `C`.  Answer the following question in your Peer Review for the week: How does the choice of `C` affect the nature of the decision boundary and the associated margin? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e38e3c2e739ce0109ca87e1c14f15c69",
     "grade": false,
     "grade_id": "cell-cc0815301b636e29",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO: Change the svm model parameter and plot the result.\n",
    "\n",
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "908df56f1476fe4ea747ccb9a429bf66",
     "grade": false,
     "grade_id": "cell-64ffe9e96f7d2afe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C**: Set `C=3` and compare the results you get when using the `hinge` vs the `squared_hinge` values for the `loss` parameter.  In this week's Peer Review Assignment: Explain your observations. Compare hinge loss vs. squared hinge loss.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bcd7f6765bbc2336b3b41535273d1cd",
     "grade": false,
     "grade_id": "cell-7828d7a24ec0edc5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO: Train the model and get the parameters, pay attention to the loss parameter\n",
    "# your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24f92ff26ef78f5480b678be90d4e796",
     "grade": false,
     "grade_id": "cell-f116bc8b54602cbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part D**: In general, how does the choice of `C` affect the bias and variance of the model? Write your answer in this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e64d8c1f6d7989f0c0b0f7a73ed3388",
     "grade": false,
     "grade_id": "cell-771d2b8c6b04fcd1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# testing cell \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9074484b9abfa995d6e9b79b25fe48da",
     "grade": false,
     "grade_id": "cell-f68a38a5526f246b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3: Nonlinear SVM, Parameter Tuning, Accuracy, and Cross-Validation \n",
    "***\n",
    "\n",
    "Any support vector machine classifier will have at least one parameter that needs to be tuned based on the training data.  The guaranteed parameter is the $C$ associated with the slack variables in the primal objective function, i.e. \n",
    "\n",
    "$$\n",
    "\\min_{{\\bf w}, b, {\\bf \\xi}} \\frac{1}{2}\\|{\\bf w}\\|^2 + C \\sum_{i=1}^m \\xi_i\n",
    "$$\n",
    "\n",
    "If you use a kernel fancier than the linear kernel then you will likely have other parameters as well. For instance in the polynomial kernel $K({\\bf x}, {\\bf z}) = ({\\bf x}^T{\\bf z} + c)^d$ you have to select the shift $c$ and the polynomial degree $d$.  Similarly the rbf kernel\n",
    "\n",
    "$$\n",
    "K({\\bf x}, {\\bf z}) = \\exp\\left[-\\gamma\\|{\\bf x} - {\\bf z}\\|^2\\right]\n",
    "$$\n",
    "\n",
    "has one tuning parameter, namely $\\gamma$, which controls how fast the similarity measure drops off with distance between ${\\bf x}$ and ${\\bf z}$. \n",
    "\n",
    "For our examples we'll consider the rbf kernel, which gives us two parameters to tune, namely $C$ and $\\gamma$. \n",
    "\n",
    "Consider the following two dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "599fd4fc1e48d31c4de9ed1562998bef",
     "grade": false,
     "grade_id": "cell-3f41670b44133217",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = part3data(N=300, seed=1235)\n",
    "nonlinear_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e40deb6ab7745b2b31821c6e9be781ce",
     "grade": false,
     "grade_id": "cell-7bca007fc3a38ff4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A**: We can use the method [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) from sklearn's `svm` module to fit an SVM with a nonlinear kernel to the data.  Go now and look at the documentation. Note that we pass the `kernel=\"rbr\"` parameter to use the RBF kernel.  The other two parameters we'll be concerned with are `C` and the RBF parameter `gamma`.   \n",
    "\n",
    "Write some code to fit an SVM with RBF kernel to the data and plot the results.  Use the parameter values `C=1` and `gamma=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e543163a7e4529273dfe13af73f9749f",
     "grade": false,
     "grade_id": "cell-adce42aa3d81a3eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "nlsvm= None\n",
    "# your code here\n",
    "\n",
    "nonlinear_plot(X, y, nlsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87ee49895719840d3aecdf880e5f12e5",
     "grade": false,
     "grade_id": "cell-17c15ee165a24978",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B**: In this part we'll use cross-validation to estimate the validation accuracy achieved by our model.  Experiment with the values of the hyperparameters to see if you can get a good validation accuracy. How do the choice of `C` and `gamma` affect the resulting decision boundary? Write your response in this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90101fa4a25c519a3263c57a09492adc",
     "grade": false,
     "grade_id": "cell-af361a2ddbbee073",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# your code here\n",
    "\n",
    "# uncomment and update nlsvm and scores\n",
    "# nlsvm =None\n",
    "# scores=0\n",
    "print(\"cross-val mean-accuracy: {:.3f}\".format(np.mean(scores)))\n",
    "nonlinear_plot(X, y, nlsvm)\n",
    "\n",
    "# C tuning\n",
    "# your code here\n",
    "\n",
    "\n",
    "# gamma tuning\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e549e33d56df0d6a124299a9dec01a47",
     "grade": false,
     "grade_id": "cell-dce482f5c8eccff0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C**: How does the choice of **kernel** function affect the bias/variance of the model? Write your answer in this week's Peer Review assignment.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ad78dfa43bd5cf64d21561dcbd92d52",
     "grade": false,
     "grade_id": "cell-ad484dfaa0cdab66",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instructor testing cell \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "790be0798a03b66e3ff30615f58312c2",
     "grade": false,
     "grade_id": "cell-57c1d6ad0baf30e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 4: Automating the Parameter Search \n",
    "***\n",
    "\n",
    "On the previous problem we were able to choose some OK parameters just by hand-tuning.  But in real life (where time is money) it would be better to do something a little more automated.  One common thing to do is a **grid-search** over a predefined range of the parameters.  In this case you will loop over all possible combinations of parameters, estimate the accuracy of your model using K-Folds cross-validation, and then choose the parameter combination that produces the highest validation accuracy. \n",
    "\n",
    "**Part A**: Below is an experiment where we search over a logarithmic range between $2^{-5}$ and $2^{5}$ for $C$ and a range between $2^{-5}$ and $2^{5}$ for $\\gamma$.  For the accuracy measure we use K-Folds CV with $K=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9a9bcfb669e9728863749076c465e43",
     "grade": false,
     "grade_id": "cell-d1c858a08a7e3b1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "grid=None # ToDo: replace it to proper GridSearchCV object and run the grid search with cross validation\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c303bb3420c3023a93ef34c643119ed",
     "grade": false,
     "grade_id": "cell-e780d11252930bd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B**: The following function will plot a heat-map of the cross-validation accuracies for each combination of parameters.  Which combination looks the best? Enter your response in this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99934202c7bcea5e6d22e50e644fa7f9",
     "grade": false,
     "grade_id": "cell-0c174922a30ab274",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plotSearchGrid(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c98ec820c5f718724b45f727e8ca10a",
     "grade": false,
     "grade_id": "cell-3a0c8e12a4b5f54e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instuctor testing cell \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7279edd4a08de1e6ce0a6d1f41670c6",
     "grade": false,
     "grade_id": "cell-d97342015823c52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C**: The GridSearchCV object scores, among other things, the best combination of parameters as well as the cross-validation accuracy achieved with those parameters.  Print those quantities for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b696a0571d94851a08e55b70db49ae7",
     "grade": false,
     "grade_id": "cell-796fb8e2baf408f5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# print best paramters and best accuracy \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7c0329b38d983a822e06aea2a6e2fe0",
     "grade": false,
     "grade_id": "cell-dfb29db96cbc8e92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part D [Peer Review]**: The GridSearchCV object also stores the classifier trained with the best hyperparameters.  Pass this best estimator into the `nonlinear_plot` function to view the best decision boundary. Answer the Peer Review questions for this section. What can you tell about the best decision boundary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e873805d20c13d54452b8f73eb3ccba6",
     "grade": false,
     "grade_id": "cell-2e1ff57c7efa556c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# pass GridSearchCV object best estimator into nonlinear_plot\n",
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
