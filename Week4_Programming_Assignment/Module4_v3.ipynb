{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47cb0b0401aabc3b1c1858711a64db4f",
     "grade": false,
     "grade_id": "cell-8ae6945a5595d011",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment item—not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment.<br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b279f49e6ddcabe7c100e2079f6e4d2",
     "grade": false,
     "grade_id": "cell-d853bae6a8cc9070",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "Please note that this assignment uses nbgrader to facilitate grading. You will see a **validate button** at the top of your Jupyter notebook. If you hit this button, it will run tests cases for the lab that aren't hidden. It is good to use the validate button before submitting the lab. Do know that the labs in the course contain hidden test cases. The validate button will not let you know whether these test cases pass. After submitting your lab, you can see more information about these hidden test cases in the Grader Output. <br>\n",
    "***Cells with longer execution times will cause the validate button to time out and freeze. Please know that if you run into Validate time-outs, it will not affect the final submission grading.*** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37683eeda215146b65f5026e9ebdb551",
     "grade": false,
     "grade_id": "cell-dbd2d13ca117f619",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Module 4: K-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6034adfae601616aef70988388e3b07",
     "grade": false,
     "grade_id": "cell-19fba0d07cf433ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the cell below to ensure that the required packages are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86084135e0186ef2a1af8d212a59371c",
     "grade": false,
     "grade_id": "cell-e64ccd51e3e81b02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# importing all the required libraries\n",
    "\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f16a22959bf9d0a98cf14df7ac88266b",
     "grade": false,
     "grade_id": "cell-703de6192d07f99f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 1 : Building a K- Nearest neighbours classifier for handwritten digit recognition [15 pts, Peer Review] \n",
    "\n",
    "In this problem you will complete some code to build a k-nearest neighbour classifier to classify images of handwritten digits (0-9). For this purpose we will use a famous open-source dataset of handwritten digits called the MNIST that is ubiquitously used for testing a number of classification algorithms in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a8b06a6e5c3891df1b08b9d4ca64867",
     "grade": false,
     "grade_id": "cell-d0067365eb87b126",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell sets up the MNIST dataset \n",
    "\n",
    "class MNIST_import:\n",
    "    \"\"\"\n",
    "    sets up MNIST dataset from OpenML \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        df = pd.read_csv(\"data/mnist_784.csv\")\n",
    "        \n",
    "        # Create arrays for the features and the response variable\n",
    "        # store for use later \n",
    "        y = df['class'].values\n",
    "        X = df.drop('class', axis=1).values\n",
    "         \n",
    "        # Convert the labels to numeric labels\n",
    "        y = np.array(pd.to_numeric(y))\n",
    "        \n",
    "        # create training and validation sets \n",
    "        self.train_x, self.train_y = X[:5000,:], y[:5000]\n",
    "        self.val_x, self.val_y = X[5000:6000,:], y[5000:6000]\n",
    "        \n",
    "data = MNIST_import()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a666bb409680d5b5b14c47c2c84b9ec2",
     "grade": false,
     "grade_id": "cell-7552f1b93c13729b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def view_digit(x, label=None):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    plt.imshow(x.reshape(28,28), cmap='gray');\n",
    "    plt.xticks([]); plt.yticks([]);\n",
    "    if label: plt.xlabel(\"true: {}\".format(label), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b23149930b1ad2b6b94c348677522b0",
     "grade": false,
     "grade_id": "cell-b5f5237b858c449d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Display a particular digit using the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33529119ce226244fd9100f80251920d",
     "grade": false,
     "grade_id": "cell-3e3b1bbbe1467ca7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_index = 9\n",
    "# your code here\n",
    "view_digit(data.train_x[training_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60097aa2e575b01c2d8d2f96e287b9cb",
     "grade": false,
     "grade_id": "cell-87383daf2fbafe0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part 1 [5 points]**\n",
    "Fill in the code in the following cell to determine the following quantities:\n",
    "   - Number of pixels in each image\n",
    "   - Number of examples in the training set\n",
    "   - Number of examples in the test set\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "253eeb6aab707aa6f5d142b8cfa226b6",
     "grade": false,
     "grade_id": "cell-217762899b37f199",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "1000\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "features = pd.DataFrame(data.train_x)\n",
    "\n",
    "\n",
    "# Here are the numbers you need to provide here:\n",
    "num_training_examples = len(features)\n",
    "num_test_examples = len(data.val_x)\n",
    "pixels_per_image = len(features.columns)\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "print(num_training_examples)\n",
    "print(num_test_examples)\n",
    "print(pixels_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c94ee92e257c294077b0b3e323a890b0",
     "grade": true,
     "grade_id": "cell-025e862a5d134f86",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests num_training_exampls, num_test_examples and pixels_per_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4dd76b46af049fb415b4c73aeafb95b5",
     "grade": false,
     "grade_id": "cell-7b3967987775d7c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have our MNIST data in the right form, let us move on to building our KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5edf1c578c77410d3249e766c8b8fe04",
     "grade": false,
     "grade_id": "cell-757b46aa24e4f614",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part 2 [10 points]**: Modify the class above to implement a KNN classifier.  There are three methods that you need to complete: \n",
    "\n",
    "- `predict`: Given an $m \\times p$ matrix of validation data with $m$ examples each with $p$ features, return a length-$m$ vector of predicted labels by calling the `classify` function on each example. \n",
    "- `classify`: Given a single query example with $p$ features, return its predicted class label as an integer using KNN by calling the `majority` function. \n",
    "- `majority`: Given an array of indices into the training set corresponding to the $K$ training examples that are nearest to the query point, return the majority label as an integer.  If there is a tie for the majority label using $K$ nearest neighbors, reduce $K$ by 1 and try again.  Continue reducing $K$ until there is a winning label. \n",
    "\n",
    "**Notes**: \n",
    "- Don't even think about implementing nearest-neighbor search or any distance metrics yourself.  Instead, go read the documentation for Scikit-Learn's [BallTree](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html) object.  You will find that its implemented [query](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree.query) method can do most of the heavy lifting for you. \n",
    "- Do not use Scikit-Learn's KNeighborsClassifier in this problem.  We're implementing this ourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f8c4e1afdbd2014ecb71dfd49ba1dc2",
     "grade": false,
     "grade_id": "cell-814a5ca0dfd2a437",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \"\"\"\n",
    "    Class to store data for regression problems \n",
    "    \"\"\"\n",
    "    def __init__(self, x_train, y_train, K=5):\n",
    "        \"\"\"\n",
    "        Creates a kNN instance\n",
    "\n",
    "        :param data: Training data consisting of train_x and train_y elements\n",
    "        :param K: The number of nearest points to consider in classification\n",
    "        \"\"\"\n",
    "        \n",
    "        # Import and build the BallTree on training features \n",
    "        from sklearn.neighbors import BallTree\n",
    "        self.balltree = BallTree(x_train)\n",
    "        \n",
    "        # Cache training labels and parameter K \n",
    "        self.y_train = y_train\n",
    "        self.K = K\n",
    "        self.x_train = x_train\n",
    "        \n",
    "        \n",
    "    def majority(self, neighbor_indices, neighbor_distances=None):\n",
    "        \"\"\"\n",
    "        Given indices of nearest neighbors in training set, return the majority label. \n",
    "        Break ties by considering 1 fewer neighbor until a clear winner is found. \n",
    "\n",
    "        :param neighbor_indices: The indices of the K nearest neighbors in self.X_train . Should be np.ndarray with shape \n",
    "            (1, k)\n",
    "        :param neighbor_distances: Corresponding distances from query point to K nearest neighbors. Should be np.ndarray\n",
    "            with shape (1, k)\n",
    "            \n",
    "        output: majority label, should be an integer\n",
    "        \"\"\"\n",
    "        \n",
    "        # your code here\n",
    "        yvals = self.y_train[neighbor_indices]\n",
    "        frequency = dict()\n",
    "        \n",
    "        for val in yvals[0]:\n",
    "            if val in frequency.keys():\n",
    "                previous_count = frequency[val]\n",
    "                frequency.update({val : previous_count + 1})\n",
    "            else:\n",
    "                frequency.update({val: 1})\n",
    "                \n",
    "        vals = np.asarray(list(frequency.values()))\n",
    "        max_val = max(vals)\n",
    "        n_at_max = np.where(vals == max_val)[0].shape[0]\n",
    "        \n",
    "        if n_at_max > 1:\n",
    "            #If there is a tie, remove the farthest neighbor by distance (if supplied), else last by index\n",
    "            if isinstance(neighbor_distances, np.ndarray):\n",
    "                farthest_neighor_distance = max(neighbor_distances[0])\n",
    "                which = np.where(neighbor_distances[0] != farthest_neighor_distance)[0]\n",
    "                new_neighbors = neighbor_indices[:, which]\n",
    "                new_neighbor_distances = neighbor_distances[:, which]\n",
    "                return(self.majority(neighbor_indices = new_neighbors, neighbor_distances = new_neighbor_distances))\n",
    "            \n",
    "            else:\n",
    "                new_neighbors = neighbor_indices[0][:-1].reshape(1, -1)\n",
    "                return(self.majority(neighbor_indices = new_neighbors, neighbor_distances = None))\n",
    "                \n",
    "        else:\n",
    "            for key, val in frequency.items():\n",
    "                if val == max_val:\n",
    "                    winner = key\n",
    "                    return(winner)\n",
    "        \n",
    "        \n",
    "    def classify(self, x):\n",
    "        \"\"\"\n",
    "        Given a query point, return the predicted label \n",
    "        \n",
    "        :param x: a query point stored as an ndarray  \n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        dist, ind = self.balltree.query(x.reshape(1, -1), k = self.K)\n",
    "        classification = self.majority(ind, dist)\n",
    "        \n",
    "        return(classification)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Given an ndarray of query points, return yhat, an ndarray of predictions \n",
    "\n",
    "        :param X: an (m x p) dimension ndarray of points to predict labels for \n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        results = list()\n",
    "        for i in range(X.shape[0]):\n",
    "            thispt = X[i, :].reshape(1, -1)\n",
    "            results.append(self.classify(thispt))\n",
    "        \n",
    "        A = np.ndarray([])\n",
    "        newA = np.append(results, A)[:-1]\n",
    "        \n",
    "        return(newA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAFDElEQVR4nO3dzyt0bRzH8XOQycavlIXyLJSNsqHZqEFZ+wdsWFlZSIrCAmmSxTRlJdYWipWUyMZCWUgpZeNppNRDFpQMc579Pd9Tc+458+tz3q/lt9N1X+nd1e1qnHE9z3MAFXWV3gAQJoKGFIKGFIKGFIKGlIYgD7uuy5UIqobnee6fM05oSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSCFoSAn0Bv8oaWxszJudnZ2Zzw4NDZlz1817wbzjOI7z/v5uzvv7+815JpMx58jHCQ0pBA0pBA0pBA0pBA0pkb/lsG4zHMdxdnd382Z+txl+jo6OzHkymTTnz8/PgdYPQ2dnpzl/eXkp807CwQkNKQQNKQQNKQQNKQQNKZG/5ZibmzPnExMTBa+xvb1tzufn583519dXwWuHZWtry5xPTU2Z87W1NXOeSqVC21MpcEJDCkFDCkFDCkFDCkFDSmRuOfr6+sz50tJSwWt8fHyY89nZWXP+8/NT8NphGRwcNOeTk5PmvK2trYS7KT9OaEghaEghaEghaEghaEiJzC3HwsKCOW9qajLn1g3F+Ph4wc9Wit/nR9rb2815Nps1535/bVPtOKEhhaAhhaAhhaAhJTK/FA4MDAR6/uTkJG92cXERaI36+npz7vfqhKB6enryZsPDw4HWODg4MOePj49/s6WK44SGFIKGFIKGFIKGFIKGlMjccgQVi8UKfjYej5vz9fV1cz42NvZXeyqG38sXNzY2yryT0uKEhhSChhSChhSChhSChpTI3HJsbm6a8729PXM+OjqaNzs/PzefTSQS5ryurnrOi52dHXN+d3dX5p2UVvX8xIEQEDSkEDSkEDSkEDSkROaWo7u7O9DzDQ35P5qRkZFAa1xdXZnzw8NDc97V1WXOZ2ZmAv27luvr66LXqAWc0JBC0JBC0JBC0JBC0JASmVsOv89sfH9/F732/v6+Oc9kMub89/fXnC8uLha9l8vLS3N+fHxc9Nq1gBMaUggaUggaUggaUggaUiJzy/H09GTOk8lkmXfi7/Pzs+g10um0Oa+mr80oJU5oSCFoSCFoSCFoSCFoSInMLUct8PuMh59cLpc3e3h4CGs7NYkTGlIIGlIIGlIIGlL4pbCKTE9PB3r+9PQ0b3ZzcxPWdmoSJzSkEDSkEDSkEDSkEDSkcMtRAS0tLea8ubk50DqpVCqM7UjhhIYUgoYUgoYUgoYUgoYUbjkqIB6Pm3O/r83IZrPm/PX1NbQ9qeCEhhSChhSChhSChhSChhTX87zCH3bdwh+Gr/v7e3Pe29trzt/e3sx5R0dHaHuqRZ7nuX/OOKEhhaAhhaAhhaAhhaAhhc9yVEAsFgv0/O3tbYl2oocTGlIIGlIIGlIIGlIIGlK45agBQb+qIso4oSGFoCGFoCGFoCGFoCGFW44akEgkzPnKykrebHV1tdTbqWqc0JBC0JBC0JBC0JDCL4UVkE6nzfny8rI5b21tNee5XC60PanghIYUgoYUgoYUgoYUgoYUXtaImsXLGiGPoCGFoCGFoCGFoCGFoCGFoCGFoCGFoCGFoCGFoCEl6F+s/Oc4zr+l2AgQ0D/WMNCHk4Bqx385IIWgIYWgIYWgIYWgIYWgIYWgIYWgIYWgIeV/V5HKxeo+kSYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_digit(data.val_x[1])\n",
    "view_digit(data.val_x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testKNN = KNN(data.train_x, data.train_y, K = 5)\n",
    "predictions = testKNN.predict(data.val_x[[1,2], :])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cd44beb24abc8bd842279bea691e098",
     "grade": true,
     "grade_id": "cell-d92321e3b2c6d5f7",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests KNN class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c9a5a7e158286b71078023d8f510af4",
     "grade": false,
     "grade_id": "cell-ce189b2957563a2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part 3 : Checking how well your classifier does**\n",
    "Use your `KNN` class to perform KNN on the validation data with $K=3$ and do the following: \n",
    "\n",
    "- **[Peer Review]** Create a **confusion matrix** (feel free to use the Scikit-Learn [confusion_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function). Upload a screenshot or copy of your confusion matrix for this week's Peer Review assignment.<br>\n",
    "**Note:** your code for this section may cause the Validate button to time out. If you want to run the Validate button prior to submitting, you could comment out the code in this section after completing the Peer Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f4c9391a02b6a0b7b558d3daf24e8d8",
     "grade": false,
     "grade_id": "cell-acaff11620e9a669",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,   0,   0,   0,   0,   0,   1,   0,   0,   0],\n",
       "       [  0, 106,   0,   0,   0,   0,   0,   1,   0,   1],\n",
       "       [  1,   2,  86,   2,   0,   0,   0,   2,   0,   0],\n",
       "       [  1,   1,   0, 111,   0,   2,   0,   0,   0,   0],\n",
       "       [  0,   2,   0,   0,  82,   0,   0,   0,   0,   4],\n",
       "       [  0,   0,   0,   2,   2,  75,   1,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1, 104,   0,   2,   0],\n",
       "       [  0,   2,   0,   0,   0,   1,   0,  93,   0,   5],\n",
       "       [  1,   1,   0,   1,   1,   0,   2,   1,  81,   1],\n",
       "       [  1,   0,   0,   1,   2,   0,   0,   2,   0, 100]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use your KNN class to perform KNN on the validation data with K = 3\n",
    "knn = KNN(data.train_x, data.train_y, K = 3)\n",
    "val_yhat = knn.predict(data.val_x)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# create a confusion matrix \n",
    "# your code here\n",
    "confusion_matrix(y_true = data.val_y, y_pred = val_yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0495640cf8371a30a7da5b25e07cefe8",
     "grade": false,
     "grade_id": "cell-92d48cabe43f95ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Based on your confusion matrix, which digits seem to get confused with other digits the most? Put your answer in this week's Peer Review assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a142e80e1e30612d3ff4717d60281f57",
     "grade": false,
     "grade_id": "cell-d7a33a558ddc8690",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Accuracy Plot [Peer Review]**: Create a plot of the accuracy of the KNN on the test set on the same set of axes for  𝐾=1,2,…,20  (feel free to go out to  𝐾=30  if your implementation is efficient enough to allow it). <br>\n",
    "Upload a copy or screenshot of the plot for this week's Peer Review assignment. <br>\n",
    "**Note:** your code for this section may cause the Validate button to time out. If you want to run the Validate button prior to submitting, you could comment out the code in this section after completing the Peer Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_accuracy(k):\n",
    "    this_model = KNN(data.train_x, data.train_y, K = k)\n",
    "    yhat = this_model.predict(data.val_x)\n",
    "    this_accuracy = accuracy_score(y_true = data.val_y, y_pred = yhat)\n",
    "    return(this_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52620d488b42fbf7c219d86081e036a2",
     "grade": false,
     "grade_id": "cell-711e2eff0fa2c38e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#acc = []\n",
    "#allks = range(1,21)\n",
    "\n",
    "#for k in allks:\n",
    "#    this_accuracy = get_accuracy(k)\n",
    "#    acc.append(this_accuracy)\n",
    "#\n",
    "# your code here\n",
    "\n",
    "# you can use this code to create your plot    \n",
    "fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(12,7))\n",
    "ax.plot(allks, acc, marker=\"o\", color=\"steelblue\", lw=3, label=\"unweighted\")\n",
    "ax.set_xlabel(\"number neighbors\", fontsize=16)\n",
    "ax.set_ylabel(\"accuracy\", fontsize=16)\n",
    "plt.xticks(range(1,31,2))\n",
    "ax.grid(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61096e84f3707ad26d803b37994e9a3f",
     "grade": false,
     "grade_id": "cell-908f560defd729eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Based on the plot, which value of K results in highest accuracy? Answer this question in this week's Peer Review assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5eb52badfea436c0e617a0f48971e33",
     "grade": false,
     "grade_id": "cell-6c04a2c214c40b6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 2: Decision Tree, post-pruning and cost complexity parameter using sklearn 0.22 [10 points, Peer Review]\n",
    "\n",
    "We will use a pre-processed natural language dataset in the CSV file \"spamdata.csv\" to classify emails as spam or not. Each row contains the word frequency for 54 words plus statistics on the longest \"run\" of captial letters.\n",
    "\n",
    "Word frequency is given by:\n",
    "\n",
    "$$ f_i = m_i / N $$\n",
    "Where $f_i$ is the frequency for word $i$, $m_i$ is the number of times word $i$ appears in the email, and $N$ is the total number of words in the email.\n",
    "\n",
    "We will use decision trees to classify the emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc1f6812e3d28419717e8254ba3dc686",
     "grade": false,
     "grade_id": "cell-9469ebbf05e61aa4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A [5 points]:** Complete the function `get_spam_dataset` to read in values from the dataset and split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0911f4c6b9a6fe2561625198c231253",
     "grade": false,
     "grade_id": "cell-f3baeed090895e48",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Need to Fix shape of ndarray outputs? Unclear\n",
    "\n",
    "from sklearn.model_selection import train_test_split as ttsplit\n",
    "\n",
    "def get_spam_dataset(filepath=\"data/spamdata.csv\", test_split=0.1):\n",
    "    '''\n",
    "    get_spam_dataset\n",
    "    \n",
    "    Loads csv file located at \"filepath\". Shuffles the data and splits\n",
    "    it so that the you have (1-test_split)*100% training examples and \n",
    "    (test_split)*100% testing examples.\n",
    "    \n",
    "    Args:\n",
    "        filepath: location of the csv file\n",
    "        test_split: percentage/100 of the data should be the testing split\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test, feature_names\n",
    "        \n",
    "        (in that order)\n",
    "        first four are  np.ndarray\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    allData = pd.read_csv(filepath, sep = \" \")\n",
    "    featureData = allData.iloc[:, :-1]\n",
    "    IsSpam = allData.iloc[:, -1]\n",
    "    label_names = allData.columns.values.tolist()\n",
    "\n",
    "    \n",
    "    numpyfeatureData = featureData.to_numpy()\n",
    "    numpyIsSpam = IsSpam.to_numpy()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(numpyfeatureData, numpyIsSpam, test_size = test_split)\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a0789333a32dedee674a1bebfddbf2e",
     "grade": false,
     "grade_id": "cell-97feaa6f4996b640",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TO-DO: import the data set into five variables: X_train, X_test, y_train, y_test, label_names\n",
    "# Uncomment and edit the line below to complete this task.\n",
    "\n",
    "test_split = 0.1 # default test_split; change it if you'd like; ensure that this variable is used as an argument to your function\n",
    "# your code here\n",
    "\n",
    "X_train, X_test, y_train, y_test, label_names = get_spam_dataset(filepath=\"data/spamdata.csv\", test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad91df4ce877aeee1d8fa2b02181d7c9",
     "grade": true,
     "grade_id": "cell-d0ee21615c2bf06e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests X_train, X_test, y_train, y_test, and label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f913d6e2d2867fe04de71bc061fe4f3",
     "grade": false,
     "grade_id": "cell-ac7a846b7ca9e011",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B[5 points]** : Build a decision tree classifier using the sklearn toolbox. Then compute metrics for performance like precision and recall. This is a binary classification problem, therefore we can label all points as either positive (SPAM) or negative (NOT SPAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5084036462271dc151260b07283fd68",
     "grade": false,
     "grade_id": "cell-146547fa0aaeaff9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "def build_dt(data_X, data_y, max_depth = None, max_leaf_nodes = None):\n",
    "    '''\n",
    "    This function builds the decision tree classifier and \n",
    "    fits it to the provided data.\n",
    "    \n",
    "    Arguments\n",
    "        data_X - a np.ndarray\n",
    "        data_y - np.ndarray\n",
    "        max_depth - None if unrestricted, otherwise an integer for the maximum\n",
    "                depth the tree can reach.\n",
    "    \n",
    "    Returns:\n",
    "        A trained DecisionTreeClassifier\n",
    "    '''    \n",
    "    # your code here\n",
    "    tree = DecisionTreeClassifier(max_depth = max_depth, max_leaf_nodes = max_leaf_nodes)\n",
    "    model = tree.fit(data_X, data_y)\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29a2871246fc9d1c2bbfb5eb2df09a03",
     "grade": true,
     "grade_id": "cell-0553f9f288fa9ab7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests build_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62e6ffd8575846c88074465417525f66",
     "grade": false,
     "grade_id": "cell-908ed30f5b48c007",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C [Peer Review]**: Here we are going to use `calculate_precision` and `calculate_recall` functions to see how these metrics change when parameters of the tree are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38e13d79f432ee27852aa6c531d14c47",
     "grade": false,
     "grade_id": "cell-e4e597da7a07ff30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def calculate_precision(y_true, y_pred, pos_label_value=1.0):\n",
    "    '''\n",
    "    This function accepts the labels and the predictions, then\n",
    "    calculates precision for a binary classifier.\n",
    "    \n",
    "    Args\n",
    "        y_true: np.ndarray\n",
    "        y_pred: np.ndarray\n",
    "        \n",
    "        pos_label_value: (float) the number which represents the postiive\n",
    "        label in the y_true and y_pred arrays. Other numbers will be taken\n",
    "        to be the non-positive class for the binary classifier.\n",
    "    \n",
    "    Returns precision as a floating point number between 0.0 and 1.0\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    precision = precision_score(y_true = y_true, y_pred = y_pred, pos_label = pos_label_value)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def calculate_recall(y_true, y_pred, pos_label_value=1.0):\n",
    "    '''\n",
    "    This function accepts the labels and the predictions, then\n",
    "    calculates recall for a binary classifier.\n",
    "    \n",
    "    Args\n",
    "        y_true: np.ndarray\n",
    "        y_pred: np.ndarray\n",
    "        \n",
    "        pos_label_value: (float) the number which represents the postiive\n",
    "        label in the y_true and y_pred arrays. Other numbers will be taken\n",
    "        to be the non-positive class for the binary classifier.\n",
    "    \n",
    "    Returns precision as a floating point number between 0.0 and 1.0\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    recall = recall_score(y_true = y_true, y_pred = y_pred, pos_label = pos_label_value)\n",
    "    \n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d54a43e52d8af89861e0f9649cbba75f",
     "grade": false,
     "grade_id": "cell-9bcac958bcd924d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "1. Modifying `max_depth`: \n",
    "    - Create a model with a shallow `max_depth` of 2. Build the model on the training set.\n",
    "    - Report precision/recall on the test set.\n",
    "    - Report depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b2c143cde976b29c7cbef81b2dd80d3",
     "grade": false,
     "grade_id": "cell-4da56f168aee9716",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Complete the first subtask for max_depth\n",
    "\n",
    "# your code here\n",
    "tree1 = build_dt(X_train, y_train, max_depth = 2)\n",
    "y_hat = tree1.predict(X_test)\n",
    "prec1 = calculate_precision(y_test, y_hat, pos_label_value=1.0)\n",
    "rec1 = calculate_recall(y_test, y_hat, pos_label_value=1.0)\n",
    "\n",
    "print(\"Tree precision is: \", prec1)\n",
    "print(\"Tree recall is: \", rec1)\n",
    "print(\"Tree depth is: \" , tree1.get_depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9cc67af060fd8be13c7d392e321d592",
     "grade": false,
     "grade_id": "cell-435dc1ed96be4a55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Submit a screenshot of your code for this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af188b551f93958b5443413c3aa08ed0",
     "grade": false,
     "grade_id": "cell-ef216e433b64fead",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "2. Modifying `max_leaf_nodes`:\n",
    "    - Create a model with a shallow `max_leaf_nodes` of 4. Build the model on the training set.\n",
    "    - Report precision/recall on the test set.\n",
    "    - Report depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36117a89f23b8f5263b11a7a83dad48b",
     "grade": false,
     "grade_id": "cell-ab9251af73821eb8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Complete the second subtask for max_depth\n",
    "\n",
    "# your code here\n",
    "tree2 = build_dt(X_train, y_train, max_leaf_nodes = 4)\n",
    "y_hat = tree2.predict(X_test)\n",
    "prec2 = calculate_precision(y_test, y_hat, pos_label_value=1.0)\n",
    "rec2 = calculate_recall(y_test, y_hat, pos_label_value=1.0)\n",
    "\n",
    "print(\"Tree precision is: \", prec2)\n",
    "print(\"Tree recall is: \", rec2)\n",
    "print(\"Tree depth is: \" , tree2.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = range(1, 10)\n",
    "prec_max_depth = []\n",
    "rec_max_depth = []\n",
    "\n",
    "for depth in max_depth:\n",
    "    this_tree = build_dt(X_train, y_train, max_depth = depth)\n",
    "    this_yhat = this_tree.predict(X_test)\n",
    "    this_prec = calculate_precision(y_test, this_yhat, pos_label_value = 1.0)\n",
    "    prec_max_depth.append(this_prec)\n",
    "    this_rec = calculate_recall(y_test, this_yhat, pos_label_value = 1.0)\n",
    "    rec_max_depth.append(this_rec)\n",
    "\n",
    "plt.plot(max_depth, prec_max_depth)\n",
    "plt.plot(max_depth, rec_max_depth)\n",
    "plt.xlabel(\"Max Depth of Classification Tree\")\n",
    "plt.ylabel(\"Precision (blue), Recall (orange)\")\n",
    "plt.title(\"Precision and Recall vs. Max Depth of Classification Tree\")\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-313fe387e17d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mthis_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mthis_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mthis_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_yhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_dt' is not defined"
     ]
    }
   ],
   "source": [
    "max_leaf_nodes = range(2, 21)\n",
    "prec_max_leaf = []\n",
    "rec_max_leaf =[]\n",
    "\n",
    "for leaf in max_leaf_nodes:\n",
    "    this_tree = build_dt(X_train, y_train, max_leaf_nodes = leaf)\n",
    "    this_yhat = this_tree.predict(X_test)\n",
    "    this_prec = calculate_precision(y_test, this_yhat, pos_label_value = 1.0)\n",
    "    prec_max_leaf.append(this_prec)\n",
    "    this_rec = calculate_recall(y_test, this_yhat, pos_label_value = 1.0)\n",
    "    rec_max_leaf.append(this_rec)\n",
    "\n",
    "plt.plot(max_leaf_nodes, prec_max_leaf)\n",
    "plt.plot(max_leaf_nodes, rec_max_leaf)\n",
    "plt.xlabel(\"Max Leaf Nodes of Classification Tree\")\n",
    "plt.ylabel(\"Precision (blue), Recall (orange)\")\n",
    "plt.title(\"Precision and Recall vs. Max Leaf Nodes of Classification Tree\")\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "327ff43b17aecaa30f8dd42e7d2bca2f",
     "grade": false,
     "grade_id": "cell-1eb1aaf40d8bd956",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In your Peer Review answer the following question: <br>\n",
    "How do precision and recall compare when you modify the max depth compared to the max number of leaf nodes? \n",
    "(Make sure to run your models a few times to get an idea). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4faed1a4f59ba6c6024ad7c8970119f4",
     "grade": false,
     "grade_id": "cell-870b3afd71a87d89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part D [Peer Review]** : In class, we used gridsearchCV to do hyperparameter tuning to select the different parameters like `max_depth` to see how our tree grows and avoids overfitting. Here, we will use cost complexity pruning parameter $\\alpha$ sklearn 0.22.1[https://scikit-learn.org/stable/user_guide.html] to prune our tree after training so as to improve accuracy on unseen data. In this exercise you will iterate over different `ccp_alpha` values and identify how performance is modulated by this parameter. <br>\n",
    "**Note:** your code for this section may cause the Validate button to time out. If you want to run the Validate button prior to submitting, you could comment out the code in this section after completing the Peer Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5993ec37f134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_complexity_pruning_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#post pruning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mccp_alphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpurities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mccp_alphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpurities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_dt' is not defined"
     ]
    }
   ],
   "source": [
    "dt = build_dt(X_train, y_train)\n",
    "\n",
    "path = dt.cost_complexity_pruning_path(X_train,y_train) #post pruning\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f738717abb9bbc962fdf9df16606fcfa",
     "grade": false,
     "grade_id": "cell-70caed0260dd7c0c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b78ac32c645c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_complexity_pruning_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#post pruning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_dt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt = build_dt(X_train, y_train)\n",
    "\n",
    "path = dt.cost_complexity_pruning_path(X_train,y_train) #post pruning\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "clfs = [] # VECTOR CONTAINING CLASSIFIERS FOR DIFFERENT ALPHAS\n",
    "# TODO: iterate over ccp_alpha values \n",
    "# your code here\n",
    "\n",
    "for alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state = 42, ccp_alpha = alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "print(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "      clfs[-1].tree_.node_count, ccp_alphas[-1]))\n",
    "\n",
    "# TODO: next, generate the train and test scores and plot the variation in these scores with increase in ccp_alpha\n",
    "# The code for plotting has been provided; edit the train_scores and test_scores variables for the right plot to be generated\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# your code here\n",
    "for model in clfs:\n",
    "    this_yhat_train = model.predict(X_train)\n",
    "    this_train_accuracy = accuracy_score(y_true = y_train, y_pred = this_yhat_train)\n",
    "    train_scores.append(this_train_accuracy)\n",
    "    \n",
    "    this_yhat_test = model.predict(X_test)\n",
    "    this_test_accuracy = accuracy_score(y_true = y_test, y_pred = this_yhat_test)\n",
    "    test_scores.append(this_test_accuracy)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
